seed: 42                      # Random seed for reproducibility

data:
  image_size: [128, 128]      # Input image size for the network
  to_rgb: true                # Convert input images to RGB

  train_roots:    # Training dataset directories
    - /home/bohdan/Документи/Samples/Images/boxing_tracker/fight_2_1/round_merged_train_only/train
    - /home/bohdan/Документи/Samples/Images/boxing_tracker/fight_2_2/round_merged_train_only/train
    - /home/bohdan/Документи/Samples/Images/boxing_tracker/fight_1_1/round_1_train/appearance_embedding
    - /home/bohdan/Документи/Samples/Images/boxing_tracker/fight_1_2/round_merged_train_only/train/

  val_root: "/home/bohdan/Документи/Samples/Images/boxing_tracker/fight_1_1/round_1_test/appearance_embedding"
  # Validation dataset directories


model:
  backbone: "mobilenetv3large" # Feature extractor backbone
  embedding_dim: 128           # Size of appearance embedding vector
  dropout: 0.1                 # Dropout rate in embedding head
  l2_reg: 0.0                  # L2 weight regularization
  train_backbone: true         # Whether to fine-tune the backbone

training:
  batch_size: 64               # Training batch size
  learning_rate: 0.0003        # Learning rate
  epochs: 20                   # Number of training epochs
  margin: 1.0                  # Margin for metric learning loss
  save_dir: "artifacts/models/apperance_cnn" # Output directory for trained model
  save_name: "apperance_encoder"       # Saved model filename
